{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:00:08.025186Z",
     "start_time": "2024-07-30T14:00:05.053713Z"
    }
   },
   "source": [
    "import rl\n",
    "import utils\n",
    "import agents\n",
    "import torch.nn as nn\n",
    "from time import sleep\n",
    "from stable_baselines3.common.torch_layers import NatureCNN"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:00:08.802368Z",
     "start_time": "2024-07-30T14:00:08.027270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vec_env = rl.setup_vec_env(\n",
    "        n_envs=8,\n",
    "        frame_skip=4,\n",
    "        action_repeat_probability=0.0,\n",
    "        frame_stacks=4,\n",
    "        seed=0,\n",
    ")\n",
    "\n",
    "callback = rl.setup_callback(vec_env, n_envs=8, eval_freq=100_000, n_eval_episodes=5)"
   ],
   "id": "95b9545409b67821",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:00:22.860444Z",
     "start_time": "2024-07-30T14:00:21.443983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name=\"impala_cnn_1400k_v2\"\n",
    "model = rl.load(path=f\"C:/Users/cgoet/PycharmProjects/Pong-RL/models/{name}\", vec_env=vec_env)"
   ],
   "id": "3eec73b85b00d8ab",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T12:21:12.395122Z",
     "start_time": "2024-07-30T12:21:11.095311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = rl.setup_model(\n",
    "        vec_env=vec_env,\n",
    "        model_class=agents.ImpalaCNN,\n",
    "        model_kwargs={\n",
    "            \"depths\": [16, 32, 64, 64, 128],\n",
    "            \"features_dim\": 512,\n",
    "            \"activation_layer\": nn.Mish,\n",
    "        },\n",
    "        net_arch={\"pi\": [64], \"vf\": [64]},\n",
    "        device=\"cuda\",\n",
    "        log_dir=\"C:/Users/cgoet/PycharmProjects/Pong-RL/logs/\",\n",
    ")"
   ],
   "id": "b07ba3e1cd6a77f6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:23:08.741242Z",
     "start_time": "2024-07-23T11:23:08.721945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = rl.setup_model(\n",
    "        vec_env=vec_env,\n",
    "        model_class=NatureCNN,\n",
    "        model_kwargs={\"features_dim\": 256},\n",
    "        net_arch={\"pi\": [64], \"vf\": [64]},\n",
    "        device=\"cuda\",\n",
    "        log_dir=\"C:/Users/cgoet/PycharmProjects/Pong-RL/logs/\",\n",
    ")"
   ],
   "id": "dc3bdea532eabff1",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:00:27.992948Z",
     "start_time": "2024-07-30T14:00:27.981916Z"
    }
   },
   "cell_type": "code",
   "source": "utils.print_model_parameters(model, shared_extractor=True)",
   "id": "81bc93e31539ff3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_extractor: 1,329,200\n",
      "pi_features_extractor: 1,329,200\n",
      "vf_features_extractor: 1,329,200\n",
      "mlp_extractor: 65,664\n",
      "action_net: 390\n",
      "value_net: 65\n",
      "Total number of parameters: 1,395,319\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# tensorboard --logdir=\"C:/Users/cgoet/PycharmProjects/Pong-RL/logs\"",
   "id": "1b7767b086f12378"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T13:14:36.473673Z",
     "start_time": "2024-07-30T12:23:29.202318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name=\"impala_cnn_1400k_v2\"\n",
    "model = rl.train(model, steps=1_000_000, name=name, new_run=True, callbacks=callback)  # start new training run"
   ],
   "id": "4341498025c8dd8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cgoet\\PycharmProjects\\Pong-RL\\.venv\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:414: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x000001F3EDF61120> != <stable_baselines3.common.vec_env.vec_frame_stack.VecFrameStack object at 0x000001F3EDCBE5F0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T16:34:33.322996Z",
     "start_time": "2024-07-30T16:29:01.778583Z"
    }
   },
   "cell_type": "code",
   "source": "model = rl.train(model, steps=100_000, name=name, new_run=False, callbacks=callback)  # continue training run",
   "id": "41d5053267b33bc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4103232, episode_reward=3.80 +/- 14.16\n",
      "Episode length: 8825.00 +/- 2155.67\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T16:34:33.416649Z",
     "start_time": "2024-07-30T16:34:33.324904Z"
    }
   },
   "cell_type": "code",
   "source": "rl.save(model, path=f\"C:/Users/cgoet/PycharmProjects/Pong-RL/models/{name}\")",
   "id": "d693b6257c34db96",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T13:18:37.022984Z",
     "start_time": "2024-07-30T13:17:48.703914Z"
    }
   },
   "cell_type": "code",
   "source": "mean_reward, std_reward = rl.evaluate(model, vec_env, episodes=10, deterministic=True)",
   "id": "57d055fa597bfc40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -17.10 +/- 3.83\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T13:20:03.704245Z",
     "start_time": "2024-07-30T13:19:13.407456Z"
    }
   },
   "cell_type": "code",
   "source": "mean_reward, std_reward = rl.evaluate(model, vec_env, episodes=10, deterministic=False)",
   "id": "adc1a6e89e3c36be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -13.30 +/- 2.83\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T16:41:15.574190Z",
     "start_time": "2024-07-30T16:38:38.953200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test model fast\n",
    "test_env = rl.setup_vec_env(\n",
    "        n_envs=1,\n",
    "        frame_skip=4,\n",
    "        action_repeat_probability=0.0,\n",
    "        frame_stacks=4,\n",
    "        seed=0,\n",
    ")\n",
    "\n",
    "delay = 1 / 24\n",
    "episodes = 1\n",
    "\n",
    "episode_rewards = []\n",
    "for episode in range(episodes):\n",
    "    # obs shape (n_envs, 40, 40, n_frame_stacks)\n",
    "    obs = test_env.reset()\n",
    "    dones = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not dones:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, dones, info = test_env.step(action)\n",
    "        total_reward += reward[0]\n",
    "        test_env.render(\"human\")\n",
    "        sleep(delay)\n",
    "        \n",
    "    episode_rewards.append(total_reward)\n",
    "    print(f\"Episode {episode} reward: {total_reward}\")"
   ],
   "id": "dd004e0e52fbea0c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cgoet\\PycharmProjects\\Pong-RL\\.venv\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:335: UserWarning: \u001B[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001B[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 reward: 21.0\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Not working correctly",
   "id": "21b78654fe7e6deb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 reward: -20.0\n",
      "Average reward: -20.0\n"
     ]
    }
   ],
   "execution_count": 14,
   "source": "rewards = rl.visualize(model=None, screen_size=screen_size, episodes=1)  # random agent",
   "id": "7420b8e48e45ef24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 reward: -21.0\n",
      "Average reward: -21.0\n"
     ]
    }
   ],
   "execution_count": 13,
   "source": "rewards = rl.visualize(model, screen_size=screen_size, episodes=1)  # trained agent",
   "id": "a414883037639b30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "Episode 0 reward: 0.0\n",
      "Average reward: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10,
   "source": [
    "env = gym.make(\n",
    "    \"ALE/Pong-v5\",\n",
    "    difficulty=None,\n",
    "    obs_type=\"rgb\",\n",
    "    frameskip=4,\n",
    "    repeat_action_probability=0.,\n",
    "    render_mode=\"human\",\n",
    ")\n",
    "input_env = WarpFrame(env, width=screen_size, height=screen_size)\n",
    "input_env = DummyVecEnv([lambda: input_env])\n",
    "input_env = VecFrameStack(input_env, n_stack=4)\n",
    "\n",
    "episode_rewards = []\n",
    "for episode in range(1):\n",
    "    obs = input_env.reset()\n",
    "    dones = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not dones:\n",
    "        obs = np.moveaxis(obs, 3, 1)\n",
    "        action, _ = model.predict(obs, deterministic=False)\n",
    "        print(action)\n",
    "        obs, reward, dones, info = input_env.step(action)\n",
    "        total_reward += reward[0]\n",
    "        break\n",
    "\n",
    "    episode_rewards.append(total_reward)\n",
    "    print(f\"Episode {episode} reward: {total_reward}\")\n",
    "\n",
    "print(f\"Average reward: {sum(episode_rewards) / len(episode_rewards)}\")\n",
    "\n",
    "episode_rewards"
   ],
   "id": "cf7515af1c38508a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
